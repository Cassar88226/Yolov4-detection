{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "Windows or Linux<br>\n",
    "CMake >= 3.12: https://cmake.org/download/<br>\n",
    "CUDA >= 10.0: https://developer.nvidia.com/cuda-toolkit-archive (on Linux do Post-installation Actions)<br>\n",
    "OpenCV >= 2.4: use your preferred package manager (brew, apt), build from source using vcpkg or download from OpenCV official site (on Windows set system variable OpenCV_DIR = C:\\opencv\\build - where are the include and x64 folders image)\n",
    "cuDNN >= 7.0 https://developer.nvidia.com/rdp/cudnn-archive (on Linux copy cudnn.h,libcudnn.so... as desribed here \n",
    "https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installlinux-tar , on Windows copy cudnn.h,cudnn64_7.dll, cudnn64_7.lib as desribed here https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installwindows )<br>\n",
    "GPU with CC >= 3.0: https://en.wikipedia.org/wiki/CUDA#GPUs_supported<br>\n",
    "on Linux GCC or Clang, on Windows MSVC 2017/2019 https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=Community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Cloning and Building Darknet\n",
    "The following cells will clone darknet from AlexeyAB's famous repository, adjust the Makefile to enable OPENCV and GPU for darknet and then build darknet.\n",
    "\n",
    "Do not worry about any warnings when you run the '!make' cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\n",
      "Built on Sat_Aug_25_21:08:04_Central_Daylight_Time_2018\n",
      "Cuda compilation tools, release 10.0, V10.0.130\n"
     ]
    }
   ],
   "source": [
    "# verify CUDA\n",
    "# !nvcc --version\n",
    "!/usr/local/cuda/bin/nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone Yolov4 darknet repo\n",
    "!git clone https://github.com/AlexeyAB/darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change makefile to have GPU and OPENCV enabled\n",
    "%cd darknet\n",
    "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
    "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
    "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
    "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make darknet (builds darknet so that you can then use the darknet executable file to run or train object detectors)\n",
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Download pre-trained YOLOv4 weights\n",
    "YOLOv4 has been trained already on the coco dataset which has 80 classes that it can predict. We will grab these pretrained weights so that we can run YOLOv4 on these pretrained classes and get detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Download COCO Dataset of special categories\n",
    "categories are person, car, bus, truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import io\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2020-12-04 12:15:38--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... failed: Name or service not known.\n",
      "wget: unable to resolve host address â€˜images.cocodataset.orgâ€™\n"
     ]
    }
   ],
   "source": [
    "# download coco dataset annotation zip file\n",
    "%cd data\n",
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip annotation zip file\n",
    "!unzip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir coco\n",
    "!mkdir coco/obj\n",
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'coco/obj'\n",
    "coco_path = 'coco'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert COCO Bounding Box to Yolov4 Format\n",
    "# COCO Bounding Box format : x(left), y(top), width, height of object\n",
    "# [477.88, 87.8, 13.7, 33.4]\n",
    "# Yolov4 Format: central x, y of object, width, height of object\n",
    "# [0.757391, 0.244731, 0.021406, 0.07822]\n",
    "# rounding 6 decimal points\n",
    "def convertBbox2YoloFormat(bbox, size):\n",
    "  width, height = size\n",
    "  x = round((bbox[0] + bbox[2]/2) / width, 6)\n",
    "  y = round((bbox[1] + bbox[3]/2) / height, 6)\n",
    "  w = round(bbox[2]/width, 6)\n",
    "  h = round(bbox[3]/height, 6)\n",
    "  return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = \"train.txt\"\n",
    "train_txt_path = os.path.join(coco_path, train_txt)\n",
    "valid_txt = \"valid.txt\"\n",
    "valid_txt_path = os.path.join(coco_path, valid_txt)\n",
    "trainfile = open(train_txt_path, 'w')\n",
    "validfile = open(valid_txt_path, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildCustomDatasetFromCOCO(annFile, description_file):\n",
    "    coco=COCO(annFile)\n",
    "    # get Category Ids\n",
    "    catNames = ['person', 'car', 'bus', 'truck']\n",
    "    catIds = coco.getCatIds(catNms=catNames)\n",
    "    # get Image Ids for 4 categories\n",
    "    imgIds = []\n",
    "    for catId in catIds:\n",
    "      sub_imgIds = coco.getImgIds(catIds=catId)\n",
    "      print(len(sub_imgIds))\n",
    "      imgIds += sub_imgIds\n",
    "    # get unique Image Ids\n",
    "    imgIds = list(set(imgIds))\n",
    "    \n",
    "    # loop Image Ids\n",
    "    # get Image Information form Coco dataset\n",
    "    for imgId in imgIds:\n",
    "        img_info = coco.loadImgs(ids = imgId)[0]\n",
    "        # Load Image and annotation\n",
    "        img = io.imread(img_info['coco_url'])\n",
    "        annIds = coco.getAnnIds(imgIds=img_info['id'], catIds=catIds, iscrowd=0)\n",
    "        anns = coco.loadAnns(annIds)\n",
    "\n",
    "        # get file name, e.g. 000000262145.jpg\n",
    "        filename = img_info['file_name']\n",
    "\n",
    "        basename = os.path.splitext(filename)[0]\n",
    "        txtfile_path = os.path.join(dataset_path, basename + '.txt')\n",
    "        # write the image path in train.txt\n",
    "        # example\n",
    "        # coco/obj/000000262145.jpg\n",
    "        # coco/obj/000000262146.jpg\n",
    "        image_path = os.path.join(dataset_path, filename)\n",
    "        description_file.write(image_path + \"\\n\")\n",
    "\n",
    "        # download image in coco/obj folder\n",
    "        io.imsave(image_path, img)\n",
    "\n",
    "        # write the yolo format bounding box in image.txt file\n",
    "        size = (img_info['width'], img_info['height'])\n",
    "        txtfile = open(txtfile_path, 'w')\n",
    "        for i, ann in enumerate(anns):      \n",
    "          bbox = convertBbox2YoloFormat(ann['bbox'], size)\n",
    "          item_str = str(catIds.index(ann['category_id']))\n",
    "          bbox_str = \" \".join(str(entry) for entry in bbox)\n",
    "          item_str += \" \" + bbox_str\n",
    "          if i != len(anns) - 1:\n",
    "            txtfile.write(item_str + \"\\n\")\n",
    "          else:\n",
    "            txtfile.write(item_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize COCO api for instance annotations\n",
    "dataDir='.'\n",
    "dataType='train2017'\n",
    "annFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)\n",
    "print(annFile)\n",
    "BuildCustomDatasetFromCOCO(annFile, trainfile)\n",
    "dataType='val2017'\n",
    "annFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)\n",
    "BuildCustomDatasetFromCOCO(annFile, validfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Write Custom Training Config for YOLOv4\n",
    "cfg/yolov4-custom.cfg\n",
    "\n",
    "cfg/coco.data\n",
    "\n",
    "data/coco.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify data/coco.names with our own categories\n",
    "person\n",
    "car\n",
    "bus\n",
    "truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify cfg/coco.data\n",
    "classes= 4\n",
    "train  = data/coco/train.txt\n",
    "valid  = data/coco/valid.txt\n",
    "names = data/coco.names\n",
    "backup = backup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify cfg/yolov4-custom.cfg\n",
    "# line 20, max_batches = 8000(4*2000)\n",
    "# line 22, steps = 6400, 7200(0.8, 0.9*8000)\n",
    "# change yolo layer classes to 4(class number), line 970, 1058, 1146\n",
    "# change filters of convolution to 27((classes + 5)x3) immediately before each 3 yolo layers, line 963, 1051, 1139"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Train the Model with Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "./darknet detector train cfg/coco.data cfg/yolov4-custom.cfg yolov4.conv.137\n",
    "# train with multiple GPU\n",
    "# ./darknet detector train cfg/coco.data cfg/yolov4-custom.cfg yolov4.conv.137 -gpus 0,1,2,3\n",
    "# If want to stop and restart training from a checkpoint:\n",
    "# ./darknet detector train cfg/coco.data cfg/yolov4-custom.cfg backup/yolov3.backup -gpus 0,1,2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6:Infer Custom Objects with Saved YOLOv4 Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define utility function\n",
    "def imShow(path):\n",
    "  import matplotlib.pyplot as plt\n",
    "  %matplotlib inline\n",
    "\n",
    "  image = cv2.imread(path)\n",
    "  height, width = image.shape[:2]\n",
    "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "  fig = plt.gcf()\n",
    "  fig.set_size_inches(18, 10)\n",
    "  plt.axis(\"off\")\n",
    "  #plt.rcParams['figure.figsize'] = [10, 5]\n",
    "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the images with trained yolov4 model\n",
    "#test out our detector!\n",
    "img_path = 'test.jpg'\n",
    "!./darknet detect cfg/yolov4-custom.cfg backup/custom-yolov4-detector_last.weights {img_path} -dont-show\n",
    "imShow('predictions.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
